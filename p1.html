<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Omics Coursework Part 1</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
        }
        .content {
            max-width: 800px;
            padding: 20px;
        }
        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 10px;
            white-space: pre-wrap; /* Allows the text to wrap */
            word-wrap: break-word;  /* Breaks long words */
            margin-top: 20px;
        }
        img {
            display: block;
            margin: 10px 0;
            max-width: 100%;
        }
    </style>
</head>
<body>
    <div class="content">
        <h1>Omics Coursework Part 1</h1>
        <p><strong>Author:</strong> Andrej Hric</p>
        <p><strong>Date:</strong> 27/07/2023</p>

        <p>All code for this coursework, along with further instructions and data, is available at my Git repository. Due to issues with hosting larger files (LSF) requiring additional storage space on GitHub, I chose to remove them for easier access. However, following the steps documented, they can be recreated.</p>
        <pre><code>Repository link: https://github.com/Andrej-Hric/Omics_coursework.git</code></pre>

        <h2>Practical Background information</h2>
        <p>The practical session involving whole-genome sequencing data, the file <code>Negative.fq</code>, extracted using specific barcodes, exhibited poor mapping results compared to other samples like <code>Positive.fq</code>. The purpose of this coursework was to analyse and explain this poor performance using best practices in NGS data handling and alignment techniques.</p>

        <h2>Environment Setup</h2>
        <p>For Part 1 of the coursework I first installed Rosetta (as I am using non-Intel based MAC), conda and all packages required and suggested by the coursework instructions for Part 1.</p>
        <pre><code>softwareupdate --install-rosetta</code></pre>

        <p>Then I installed Conda, created an environment for this coursework and installed all packages required based on the coursework instructions.</p>
        <pre><code>conda init
conda create --name omics_cw_env python=3.9
conda activate omics_cw_env
conda install -c bioconda cutadapt bowtie2 samtools fastqc multiqc</code></pre>

        <p>I used conda and created new environment to ensure that there are no software dependencies conflict which I found to be issue originally when not using conda. Also having this specific environment I could call it whenever necessary in future.</p>

        <h2>Issues with original reads and improving of the mapping</h2>
        <p>I ran FastQC report on Negative.fq file which we want to analyze in detail from practical</p>
        <pre><code>cd input_data/p1/fastq
fastqc trimmed_Negative.fq</code></pre>
        <p>The report from the practical on Negative.fq only showed problems with 1. Per base sequence quality and 2. Per base N content shown below. The fastqc report showed issues with bp positions [1-6] and [56-59] which are the 5' and 3' ends of the reads. The N base content showed that these bases were classified as other than ACTG bases and labelled as N due to low confidence of the base being one of the four main bases.</p>

        <img src="https://github.com/Andrej-Hric/Omics_coursework/raw/main/images_html/trimmed_negative_fastq_images/per_base_quality.png" alt="Per Base Quality">
        <img src="https://github.com/Andrej-Hric/Omics_coursework/raw/main/images_html/trimmed_negative_fastq_images/per_base_n_content.png" alt="Per Base N Content">

        <p>Next I performed an alignment as in the practical with the same settings this was --end-to-end. However, this alignment failed as it was unable to find a match to the reference genome. This is why I assumed that this is due to the bases at positions [1-6] and [56-59] as indicated by the fastQC report so the first five on 5' and last four on 3' ends. I then also performed a local alignment instead which could be a solution however the alignment result ended up having 0.00% alignment rate.</p>

        <p>This is why I then performed another alignment however specifying start/end positions, effectively ignoring the end bp which caused the issue not being able to align with the reference genome. This showed that the new alignment was successfully aligned with the reference genome to a 99.97% alignment rate.</p>

        <p>This was quite a significant improvement compared to original 0.00% proving that the alignment problem was caused by the N base read calls.</p>

        <p>For all of this I used bowtie2 and commands shown below.</p>
        <pre><code>bowtie2 --end-to-end --all -x input/p1/genome/AFPN02.1_merge -q input/p1/fastq/trimmed_Negative.fq -S output/p1/Negative_local.sam >& output/p1/Negative_local_bowtie_output_statistics.txt</code></pre>
        <pre><code>bowtie2 --local --all -x input/p1/genome/AFPN02.1_merge -q input/p1/fastq/trimmed_Negative.fq -S output/p1/Negative_local.sam >& output/p1/Negative_local_bowtie_output_statistics.txt
# note : the original alignment txt file was overwritten as the results showed no alignment
# (can solve this by renaming the output file differently)

-Results from Negative_local_bowtie_output_statistics.txt file of these alignments
""" 
    1076320 reads; of these:
        1076320 (100.00%) were unpaired; of these:
            1076320 (100.00%) aligned 0 times
            0 (0.00%) aligned exactly 1 time
            0 (0.00%) aligned >1 times
        0.00% overall alignment rate
""" </code></pre>
        <pre><code>bowtie2 --end-to-end --all -x input/p1/genome/AFPN02.1_merge -q input/p1/fastq/trimmed_Negative.fq -5 5 -3 4 -S output/p1/Negative_trim.sam >& output/p1/Negative_local_bowtie_output_statistics.txt

-Improved results of specific alignment
""" 
    1076320 reads; of these:
        1076320 (100.00%) were unpaired; of these:
            308 (0.03%) aligned 0 times
            1020237 (94.79%) aligned exactly 1 time
            55775 (5.18%) aligned >1 times
        99.97% overall alignment rate
""" </code></pre>

        <p>I then produced a new fastQC report as shown below. This Report now has high quality for all positions, compared to the previous fastQC of the untrimmed Negative.fq. Also, the summary.txt file provided when unzipping the fastQC file showed that all tests were passed. The fastQC report is shown below along with the summary.txt content</p>

        <img src="https://github.com/Andrej-Hric/Omics_coursework/raw/main/images_html/New_base_trimmed_fastq_images/per_base_quality.png" alt="New Base Trimmed Per Base Quality">

        <pre><code>PASS    Basic Statistics    NEW_base_trimmed_Negative.fq
PASS    Per base sequence quality    NEW_base_trimmed_Negative.fq
PASS    Per sequence quality scores    NEW_base_trimmed_Negative.fq
PASS    Per base sequence content    NEW_base_trimmed_Negative.fq
PASS    Per sequence GC content    NEW_base_trimmed_Negative.fq
PASS    Per base N content    NEW_base_trimmed_Negative.fq
PASS    Sequence Length Distribution    NEW_base_trimmed_Negative.fq
PASS    Sequence Duplication Levels    NEW_base_trimmed_Negative.fq
PASS    Overrepresented sequences    NEW_base_trimmed_Negative.fq
PASS    Adapter Content    NEW_base_trimmed_Negative.fq</code></pre>

        <p>With this information I could proceed to a new alignment as all information seemed correct up until this point.</p>

        <h2>Remapping based on N calls being the problem</h2>
        <p>To replicate the alignment score and prove my hypothesis I produced a new file trimming 5' and 3' ends and also all N calls, effectively to eliminate any issue causing bases.</p>
        <pre><code># remove all N calls and first 5 and last 4 positions
cutadapt --trim-n --trim5 5 --trim3 4 -o input_data/p1/fastq/NEW_base_trimmed_Negative.fq input_data/p1/fastq/trimmed_Negative.fq

# new alignment
bowtie2 --end-to-end --all -x input_data/p1/genomes/AFPN02.1_merge -q input_data/p1/fastq/NEW_base_trimmed_Negative.fq -S output_data/p1/New_Negative_trim.sam >& output_data/p1/New_Negative_trim_bowtie_output_statistics.txt

-Results
""" 
    1076320 reads; of these:
        1076320 (100.00%) were unpaired; of these:
            308 (0.03%) aligned 0 times
            1020237 (94.79%) aligned exactly 1 time
            55775 (5.18%) aligned >1 times
        99.97% overall alignment rate
""" </code></pre>

        <h2>FINAL mapping statistics</h2>
        <p>To get the mapping statistics I looked up samtools commands for this.</p>
        <pre><code># first I converted SAM files to BAM format for more efficient handling and processing as BAM file is smaller and faster and recommended to use for samtool

samtools view -bS output_data/p1/New_Negative_trim.sam | samtools sort -o output_data/p1/New_Negative_trim_sorted.bam 

# then to index the bam file 
samtools index output_data/p1/New_Negative_trim_sorted.bam

# after indexing the bam files, statistics can be extracted and we can look at alignment quality stats.
samtools stats output_data/p1/New_Negative_trim_sorted.bam > output_data/p1/New_Negative_trim_stats.txt

# flagstat analysis used as recommended by the coursework 
samtools flagstat output_data/p1/New_Negative_trim_sorted.bam > output_data/p1/New_Negative_trim_flagstats.txt

# lastly again as recommended I used MultiQC to summarize the statistics and generate a report, this should contain all data from quality control and alignment.
multiqc output_data/p1/ -o output_data/p1/multiqc_report</code></pre>

        <p>By doing this I could resolve the question why the original figure in the coursework, of Negative_bowtie_stats and Positive_bowtie_stats were different, and I ended up with exactly the same result of Negative_bowtie_stats as Positive_bowtie_stats in the original Bowtie 2 SE alignment scores. This is shown on the image below.</p>

        <img src="https://github.com/Andrej-Hric/Omics_coursework/raw/main/images_html/bowtie2_se_plot.png" alt="Bowtie2 SE Plot">

        <h2>Conclusion of coursework P1</h2>
        <p>In my genomic sequencing analysis, I initially attempted to align the reads using bowtie2 without preprocessing. This direct approach resulted in an alignment rate of 0%, which was quite disappointing. The FastQC analysis had already shown that the extremities of the reads were plagued with ‘N’ bases which are indicators that represent uncertainty in nucleotide identity. These ‘N’ bases, found primarily at the 5’ and 3’ ends, effectively hindered proper alignment to the reference genome, as they obscured the true biological sequences.</p>

        <p>Considering these challenges, I decided to implement a trimming strategy. I trimmed the first 5 bases from the 5’ end and the last 4 bases from the 3’ end of each read, targeting precisely those regions flagged by FastQC. I think this approach was necessary to get rid of the problematic bases which were causing misalignments. This adjustment improved the alignment rate to 99.97%. I consider the trimmed alignment method better and easier as when I removed these problem N sections, the reads aligned closely to the genome, demonstrating the substantial impact that even simple preprocessing steps can have on the quality and utility of NGS data. This experience has reinforced my belief in the critical role of preprocessing in enhancing the accuracy of genomic analyses.</p>
    </div>
</body>
</html>
